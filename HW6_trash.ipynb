{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "#origin  y = 10 + x*x\n",
    "def get_y(x):\n",
    "    # x1 - cos(0.2*pi*x2) = 0.5\n",
    "    #return x1\n",
    "    pi = 3.141592654\n",
    "    #return 0.5 + math.cos(0.2*pi*x)\n",
    "    return x\n",
    "    \n",
    "\n",
    "\n",
    "def sample_data(n=10000, scale=100):\n",
    "    data = []\n",
    "\n",
    "    x = scale*(np.random.random_sample((n,))-0.5)\n",
    "\n",
    "    for i in range(n):\n",
    "        yi = get_y(x[i])\n",
    "        #data.append([x[i], yi])\n",
    "        data.append([x[i],yi])\n",
    "\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = sample_data(10000,10)\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_noise = t + 0.3 * np.random.normal(loc=0, scale=1, size=t.shape)\n",
    "t_noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jeff/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# compress dim to 1\n",
    "encoding_dim = 1\n",
    " \n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(2,))\n",
    " \n",
    "# encode\n",
    "encoded = Dense(128, activation='relu')(input_img)\n",
    "encoded = Dense(64, activation='relu')(encoded)\n",
    "encoder_output = Dense(encoding_dim, activation='relu')(encoded)\n",
    " \n",
    "# decode\n",
    "decoded = Dense(64, activation='relu')(encoder_output)\n",
    "decoded = Dense(128, activation='relu')(decoded)\n",
    "decoded = Dense(2, activation='sigmoid')(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compress dim to 1\n",
    "encoding_dim = 1\n",
    " \n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(2,))\n",
    " \n",
    "# encode\n",
    "encoder_output = Dense(encoding_dim, activation='relu')(input_img)\n",
    " \n",
    "# decode\n",
    "decoded = Dense(2, activation='sigmoid')(encoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 3         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 4         \n",
      "=================================================================\n",
      "Total params: 7\n",
      "Trainable params: 7\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 2s 194us/sample - loss: 8.8587\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 0s 25us/sample - loss: 8.8095\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 8.7620\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 8.7176\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 8.6765\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 8.6387\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 8.6043\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 8.5719\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 8.5416\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 8.5128\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 8.4853\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 0s 22us/sample - loss: 8.4584\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 8.4320\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 8.4054\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 8.3770\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 0s 10us/sample - loss: 8.3449\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 8.3037\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 0s 22us/sample - loss: 8.2397\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 0s 25us/sample - loss: 8.1204\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 7.9039\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 0s 23us/sample - loss: 7.5921\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 7.3011\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 7.1323\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 7.0434\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 6.9884\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 0s 22us/sample - loss: 6.9486\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 6.9169\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 0s 24us/sample - loss: 6.8900\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 0s 24us/sample - loss: 6.8661\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 0s 19us/sample - loss: 6.8446\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 6.8249\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 6.8066\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 6.7893\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 6.7732\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 6.7578\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 6.7432\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 6.7294\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 6.7162\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 6.7036\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 6.6916\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 6.6800\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 6.6688\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 0s 25us/sample - loss: 6.6581\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 6.6478\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 0s 23us/sample - loss: 6.6379\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 0s 19us/sample - loss: 6.6283\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 0s 20us/sample - loss: 6.6191\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 0s 21us/sample - loss: 6.6102\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 0s 25us/sample - loss: 6.6017\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 0s 20us/sample - loss: 6.5935\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 0s 24us/sample - loss: 6.5855\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 0s 20us/sample - loss: 6.5777\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 0s 19us/sample - loss: 6.5702\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 0s 19us/sample - loss: 6.5631\n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 0s 21us/sample - loss: 6.5562\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 6.5494\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 6.5429\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 0s 20us/sample - loss: 6.5367\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 6.5306\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 0s 21us/sample - loss: 6.5247\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 0s 19us/sample - loss: 6.5188\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 6.5133\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 6.5079\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 6.5027\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 6.4976\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 6.4926\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 6.4878\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 0s 19us/sample - loss: 6.4832\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 0s 19us/sample - loss: 6.4786\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 6.4742\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 6.4699\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 6.4658\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 6.4617\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 6.4578\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 6.4539\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 6.4502\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 6.4465\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 0s 22us/sample - loss: 6.4429\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 0s 20us/sample - loss: 6.4395\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 0s 25us/sample - loss: 6.4361\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 0s 19us/sample - loss: 6.4328\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 0s 25us/sample - loss: 6.4296\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 0s 22us/sample - loss: 6.4264\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 0s 20us/sample - loss: 6.4234\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 0s 23us/sample - loss: 6.4204\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 0s 26us/sample - loss: 6.4176\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 0s 25us/sample - loss: 6.4148\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 6.4120\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 6.4093\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 6.4067\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 6.4042\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 13us/sample - loss: 6.4017\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 6.3993\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 6.3969\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 0s 25us/sample - loss: 6.3946\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 0s 21us/sample - loss: 6.3923\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 6.3901\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 6.3879\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 6.3858\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 0s 22us/sample - loss: 6.3837\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff84d334710>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct model\n",
    "autoencoder = Model(inputs=input_img, outputs=decoded)\n",
    " \n",
    "# construct encoder \n",
    "encoder = Model(inputs=input_img, outputs=encoder_output)\n",
    "\n",
    "# compile autoencoder\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    " \n",
    "# training\n",
    "autoencoder.fit(t_noise,t, epochs=100, batch_size=256, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model inputs must come from `tf.keras.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"model_2\" was not an Input tensor, it was generated by layer dense_6.\n",
      "Note that input tensors are instantiated via `tensor = tf.keras.Input(shape)`.\n",
      "The tensor that caused the issue was: dense_6/Relu:0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Graph disconnected: cannot obtain value for tensor Tensor(\"input_2:0\", shape=(?, 2), dtype=float32) at layer \"input_2\". The following previous layers were accessed without issue: []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c65e60a1fc2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     \u001b[0;31m# initializing _distribution_strategy here since it is possible to call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;31m# predict on a model without compiling it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m         'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[1;32m    161\u001b[0m       \u001b[0;31m# Graph network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m       \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs, name, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     nodes, nodes_by_depth, layers, layers_by_depth = _map_graph_network(\n\u001b[0;32m--> 315\u001b[0;31m         self.inputs, self.outputs)\n\u001b[0m\u001b[1;32m    316\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1848\u001b[0m                              \u001b[0;34m'The following previous layers '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                              \u001b[0;34m'were accessed without issue: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1850\u001b[0;31m                              str(layers_with_complete_input))\n\u001b[0m\u001b[1;32m   1851\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m           \u001b[0mcomputable_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor Tensor(\"input_2:0\", shape=(?, 2), dtype=float32) at layer \"input_2\". The following previous layers were accessed without issue: []"
     ]
    }
   ],
   "source": [
    "\n",
    "# decoder\n",
    "decoder = Model(inputs=encoder_output, outputs=decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting\n",
    "autoencoder_out = autoencoder.predict(t)\n",
    "plt.scatter(t[:,0],t[:,1])\n",
    "plt.scatter(autoencoder_out[:, 0], autoencoder_out[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
